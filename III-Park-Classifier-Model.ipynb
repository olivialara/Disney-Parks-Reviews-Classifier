{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210c1b8-4a0b-4e70-bf78-0c9cc201cd7c",
   "metadata": {},
   "source": [
    "# Project 5: Disneyland Park and Rating Classifier\n",
    "## Part III: Park Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060b2d6-af42-42fe-b618-2387d0e010be",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6508f4-b7e5-4cc1-8e6e-648e26ee1034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# essentials:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "# plotly:\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# scikit-learn:\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, f1_score, balanced_accuracy_score, accuracy_score, RocCurveDisplay, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import VotingRegressor, BaggingClassifier, BaggingRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier, HistGradientBoostingClassifier, HistGradientBoostingRegressor \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# NN & NLP scikit-learn:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import fetch_openml, make_classification, make_regression\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# unsupervised learning scikit-learn:\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_distances, cosine_similarity\n",
    "\n",
    "# imblearn:\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, SMOTENC\n",
    "\n",
    "# API & Webscraping:\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# nltk:\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.chunk import tree2conlltags\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# tensorflow/keras:\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# time series/sktime:\n",
    "import sktime\n",
    "import statsmodels\n",
    "import pmdarima as pmd\n",
    "import pandas_datareader as pdr\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sktime.forecasting.compose import EnsembleForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "\n",
    "# spacy: \n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "# statsmodels:\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# emojis:\n",
    "import emoji\n",
    "import demoji\n",
    "\n",
    "# others:\n",
    "import scipy.stats as stats\n",
    "import missingno as msno\n",
    "from itertools import groupby\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66e5e1-0dbc-4abb-85c3-a58ed22816fd",
   "metadata": {},
   "source": [
    "### 2. Read in & Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1253625-b7a1-4a54-8fe7-36701364df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disney = pd.read_csv('../data/Clean_DisneylandReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaacc98-6232-42b1-952f-f0cdc17cbd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch</th>\n",
       "      <th>park</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>tb_polarity</th>\n",
       "      <th>vs_polarity</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>3</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>if you've ever been to disneyland anywhere you...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0.561481</td>\n",
       "      <td>0.239352</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>3</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>its been a while since d last time we visit hk...</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>0.459783</td>\n",
       "      <td>0.205797</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>3</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>thanks god it wasn t too hot or too humid when...</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>0.434857</td>\n",
       "      <td>0.119238</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>3</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>hk disneyland is a great compact park unfortun...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>3</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>the location is not in the city took around 1 ...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Branch  park  \\\n",
       "0  Disneyland_HongKong     3   \n",
       "1  Disneyland_HongKong     3   \n",
       "2  Disneyland_HongKong     3   \n",
       "3  Disneyland_HongKong     3   \n",
       "4  Disneyland_HongKong     3   \n",
       "\n",
       "                                         Review_Text  \\\n",
       "0  If you've ever been to Disneyland anywhere you...   \n",
       "1  Its been a while since d last time we visit HK...   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...   \n",
       "3  HK Disneyland is a great compact park. Unfortu...   \n",
       "4  the location is not in the city, took around 1...   \n",
       "\n",
       "                                          clean_text     Reviewer_Location  \\\n",
       "0  if you've ever been to disneyland anywhere you...             Australia   \n",
       "1  its been a while since d last time we visit hk...           Philippines   \n",
       "2  thanks god it wasn t too hot or too humid when...  United Arab Emirates   \n",
       "3  hk disneyland is a great compact park unfortun...             Australia   \n",
       "4  the location is not in the city took around 1 ...        United Kingdom   \n",
       "\n",
       "  Year_Month  year month  text_word_count  subjectivity  tb_polarity  \\\n",
       "0     2019-4  2019     4               59      0.561481     0.239352   \n",
       "1     2019-5  2019     5              171      0.459783     0.205797   \n",
       "2     2019-4  2019     4              169      0.434857     0.119238   \n",
       "3     2019-4  2019     4               91      0.512143     0.189286   \n",
       "4     2019-4  2019     4               31      0.437500     0.266667   \n",
       "\n",
       "   vs_polarity  Rating  \n",
       "0       0.6786       4  \n",
       "1       0.9879       4  \n",
       "2       0.9945       4  \n",
       "3       0.8489       4  \n",
       "4       0.2846       4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a05d3c8-d71c-4094-8061-83a89f889bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42656 entries, 0 to 42655\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Branch             42656 non-null  object \n",
      " 1   park               42656 non-null  int64  \n",
      " 2   Review_Text        42656 non-null  object \n",
      " 3   clean_text         42656 non-null  object \n",
      " 4   Reviewer_Location  42656 non-null  object \n",
      " 5   Year_Month         42656 non-null  object \n",
      " 6   year               42656 non-null  object \n",
      " 7   month              42656 non-null  object \n",
      " 8   text_word_count    42656 non-null  int64  \n",
      " 9   subjectivity       42656 non-null  float64\n",
      " 10  tb_polarity        42656 non-null  float64\n",
      " 11  vs_polarity        42656 non-null  float64\n",
      " 12  Rating             42656 non-null  int64  \n",
      "dtypes: float64(3), int64(3), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "disney.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e3072a-d488-4c82-a4b4-9ad758cdc02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>tb_polarity</th>\n",
       "      <th>vs_polarity</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42656.000000</td>\n",
       "      <td>42656.000000</td>\n",
       "      <td>42656.000000</td>\n",
       "      <td>42656.000000</td>\n",
       "      <td>42656.000000</td>\n",
       "      <td>42656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.770583</td>\n",
       "      <td>129.703817</td>\n",
       "      <td>0.524574</td>\n",
       "      <td>0.212199</td>\n",
       "      <td>0.680870</td>\n",
       "      <td>4.217695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.792370</td>\n",
       "      <td>154.713032</td>\n",
       "      <td>0.124134</td>\n",
       "      <td>0.175264</td>\n",
       "      <td>0.477683</td>\n",
       "      <td>1.063371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.997700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.450786</td>\n",
       "      <td>0.105354</td>\n",
       "      <td>0.640925</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.519638</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.594202</td>\n",
       "      <td>0.311590</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3963.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               park  text_word_count  subjectivity   tb_polarity  \\\n",
       "count  42656.000000     42656.000000  42656.000000  42656.000000   \n",
       "mean       1.770583       129.703817      0.524574      0.212199   \n",
       "std        0.792370       154.713032      0.124134      0.175264   \n",
       "min        1.000000         3.000000      0.000000     -1.000000   \n",
       "25%        1.000000        45.000000      0.450786      0.105354   \n",
       "50%        2.000000        81.000000      0.519638      0.203333   \n",
       "75%        2.000000       156.000000      0.594202      0.311590   \n",
       "max        3.000000      3963.000000      1.000000      1.000000   \n",
       "\n",
       "        vs_polarity        Rating  \n",
       "count  42656.000000  42656.000000  \n",
       "mean       0.680870      4.217695  \n",
       "std        0.477683      1.063371  \n",
       "min       -0.997700      1.000000  \n",
       "25%        0.640925      4.000000  \n",
       "50%        0.895700      5.000000  \n",
       "75%        0.966100      5.000000  \n",
       "max        0.999900      5.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492de39-bf9e-4e90-b329-dc57f2b5c027",
   "metadata": {},
   "source": [
    "### 3. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e379c1-7b8f-41cf-8a5b-9921e26aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = disney['clean_text']\n",
    "y = disney['park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82aa0d5d-bc38-421e-aaf7-8048c8b8ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4efd340-71c8-42e6-98fd-0374c3e3dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.454926\n",
       "2    0.319549\n",
       "3    0.225525\n",
       "Name: park, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bab94d-a958-47b7-907e-256aee0b3ffe",
   "metadata": {},
   "source": [
    "The goal is to beat baseline of .45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c226617-736e-477e-916e-b699261fa92b",
   "metadata": {},
   "source": [
    "### 4. Functions for Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50683dab-a01a-4086-8e59-4f7f7be3118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lemmatizes text\n",
    "\n",
    "def split_into_lemmas(text):\n",
    "    '''return lowercased, lemmatizeed list of words as a string from a document passed in '''\n",
    "   \n",
    "    text = text.lower()\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmer.lemmatize(word) for word in text.split() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e6662e-0933-43b2-a3ac-3530865b4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that stems sentence to make it more understandable\n",
    "\n",
    "def stem_sentence(sentence): \n",
    "    \n",
    "    p_stemmer = PorterStemmer()\n",
    "    return ' '.join([p_stemmer.stem(word) for word in sentence.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9dbab1e-9e6d-4033-abee-155203a30128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that does train test split, creates a pipline, and scores the given model with transformer\n",
    "# this function assumes X has one feature: clean_text\n",
    "\n",
    "def model_score(transformer, classifier, X,y):\n",
    "    # train, test, split X and y \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 4, stratify = y)\n",
    "    \n",
    "    # make pipeline\n",
    "    pipe = make_pipeline(transformer, classifier)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # define score\n",
    "    test_score = np.round(pipe.score(X_test, y_test), 3)\n",
    "    \n",
    "    # print model and score\n",
    "    print (f' model: {transformer, classifier}')\n",
    "    return (f' test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26543033-917e-4743-9e1f-f2318012e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that does train test split, creates a pipline, and scores the given model with transformer\n",
    "# this function assumes X has more than one feature\n",
    "\n",
    "def model_score_more_feats(transformer, classifier, X,y):\n",
    "    # train, test, split X and y \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 4, stratify = y)\n",
    "    \n",
    "    # make transformer\n",
    "    ct = make_column_transformer((transformer, 'clean_text'), remainder='passthrough')\n",
    "    \n",
    "    # make pipeline\n",
    "    pipe = make_pipeline(ct, StandardScaler(with_mean=False), classifier)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # define score\n",
    "    test_score = np.round(pipe.score(X_test, y_test), 3)\n",
    "    \n",
    "    # print model and score\n",
    "    print (f' model: {transformer, classifier}')\n",
    "    return (f' test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d204f0-1af0-428f-bb38-fb9acc958c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that helps guage which hyperparameters to tune in order to avoid running too many parameters in Grid Search\n",
    "\n",
    "def count_vec_options(classifier, X, y):\n",
    "    # count vectorizer\n",
    "    print(model_score(CountVectorizer(), classifier, X, y))\n",
    "    print(model_score(CountVectorizer(stop_words = 'english'),classifier, X, y))\n",
    "    print(model_score(CountVectorizer(stop_words = 'english', max_features = 1_000), classifier, X, y))\n",
    "    print(model_score(CountVectorizer(preprocessor=split_into_lemmas), classifier, X, y))\n",
    "    print(model_score(CountVectorizer(preprocessor=stem_sentence), classifier, X, y))\n",
    "    print(model_score(CountVectorizer(ngram_range=(1,2)), classifier, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f28dac-ecce-4775-a749-799cc4ee2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that helps guage which hyperparameters to tune in order to avoid running too many parameters in Grid Search\n",
    "\n",
    "def tfidf_vec_options(classifier, X, y):\n",
    "   # tfidf vectorizer\n",
    "    print(model_score(TfidfVectorizer(), classifier, X, y))\n",
    "    print(model_score(TfidfVectorizer(stop_words = 'english'), classifier, X, y))\n",
    "    print(model_score(TfidfVectorizer(stop_words = 'english', max_features = 1_000), classifier, X, y))\n",
    "    print(model_score(TfidfVectorizer(preprocessor=split_into_lemmas), classifier, X, y))\n",
    "    print(model_score(TfidfVectorizer(preprocessor=stem_sentence), classifier, X, y))\n",
    "    print(model_score(TfidfVectorizer(ngram_range=(1,2)), classifier, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de8444-086e-478f-95f6-269fdbdc8d9f",
   "metadata": {},
   "source": [
    "### 5. Testing Models with Different X's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0318dcd6-f7e8-4301-a9a2-438c8af080a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=4, max_iter = 10_000)\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier(random_state=4)\n",
    "bag = BaggingClassifier(random_state=4)\n",
    "rfc = RandomForestClassifier(random_state=4)\n",
    "ada = AdaBoostClassifier(random_state=4)\n",
    "gb = GradientBoostingClassifier(random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae2e3176-6703-4afe-a9e1-7b83fab62d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, knn, dtc, bag, rfc, ada, gb]\n",
    "models = [lr, knn, dtc, bag, rfc, ada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a1a214d-9ed8-4c92-b4ce-4920331fdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = disney['clean_text']\n",
    "y = disney['park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd2cfa6a-8b7f-4169-97ec-51320f6222f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model: (CountVectorizer(), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.858\n",
      " model: (CountVectorizer(), KNeighborsClassifier())\n",
      " test score: 0.538\n",
      " model: (CountVectorizer(), DecisionTreeClassifier(random_state=4))\n",
      " test score: 0.719\n",
      " model: (CountVectorizer(), BaggingClassifier(random_state=4))\n",
      " test score: 0.778\n",
      " model: (CountVectorizer(), RandomForestClassifier(random_state=4))\n",
      " test score: 0.781\n",
      " model: (CountVectorizer(), AdaBoostClassifier(random_state=4))\n",
      " test score: 0.777\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model_score(CountVectorizer(), model, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f57a462-a450-420e-be58-fe18c416b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = disney[['clean_text', 'text_word_count', 'subjectivity', 'tb_polarity', 'vs_polarity']]\n",
    "y = disney['park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62d3a552-02c6-4757-904d-f27d478887a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model: (CountVectorizer(), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.761\n",
      " model: (CountVectorizer(), KNeighborsClassifier())\n",
      " test score: 0.532\n",
      " model: (CountVectorizer(), DecisionTreeClassifier(random_state=4))\n",
      " test score: 0.716\n",
      " model: (CountVectorizer(), BaggingClassifier(random_state=4))\n",
      " test score: 0.774\n",
      " model: (CountVectorizer(), RandomForestClassifier(random_state=4))\n",
      " test score: 0.778\n",
      " model: (CountVectorizer(), AdaBoostClassifier(random_state=4))\n",
      " test score: 0.779\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model_score_more_feats(CountVectorizer(), model, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21607d-03b3-40c3-8d5e-d0ea3683a1e4",
   "metadata": {},
   "source": [
    "### 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65c2f639-4fd0-410e-ad96-291de5dacfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model: (CountVectorizer(), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.858\n",
      " model: (CountVectorizer(stop_words='english'), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.857\n",
      " model: (CountVectorizer(max_features=1000, stop_words='english'), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.841\n",
      " model: (CountVectorizer(preprocessor=<function split_into_lemmas at 0x1ab33d820>), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.861\n",
      " model: (CountVectorizer(preprocessor=<function stem_sentence at 0x110712a60>), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.859\n",
      " model: (CountVectorizer(ngram_range=(1, 2)), LogisticRegression(max_iter=10000, random_state=4))\n",
      " test score: 0.863\n"
     ]
    }
   ],
   "source": [
    "count_vec_options(lr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189356f-57b3-4839-bdef-a4d82d922d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
